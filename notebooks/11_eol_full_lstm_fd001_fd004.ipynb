{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    import torch  # type: ignore[import]\n",
        "    import torch.nn as nn  # type: ignore[import]\n",
        "    from torch.utils.data import TensorDataset, DataLoader, random_split  # type: ignore[import]\n",
        "except ImportError as exc:\n",
        "    raise ImportError(\n",
        "        \"PyTorch is required for this notebook. Please install torch.\"\n",
        "    ) from exc\n",
        "\n",
        "try:\n",
        "    from sklearn.preprocessing import MinMaxScaler, StandardScaler  # type: ignore[import]\n",
        "except ImportError as exc:\n",
        "    raise ImportError(\n",
        "        \"scikit-learn is required for this notebook. Please install scikit-learn.\"\n",
        "    ) from exc\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "import sys\n",
        "root_dir = os.path.abspath(\"..\")\n",
        "if root_dir not in sys.path:\n",
        "    sys.path.append(root_dir)\n",
        "\n",
        "from src.config import (\n",
        "    CMAPSS_DATASETS,\n",
        "    MAX_RUL,\n",
        "    SEQUENCE_LENGTH,\n",
        "    HIDDEN_SIZE,\n",
        "    NUM_LAYERS,\n",
        "    OUTPUT_SIZE,\n",
        "    LEARNING_RATE,\n",
        "    NUM_EPOCHS,\n",
        "    GLOBAL_FEATURE_COLS,\n",
        "    GLOBAL_DROP_COLS \n",
        ")\n",
        "\n",
        "from src.data_loading import load_cmapps_subset\n",
        "from src.additional_features import create_physical_features\n",
        "from src.eol_full_lstm import (\n",
        "    build_full_eol_sequences_from_df,\n",
        "    create_full_dataloaders,\n",
        "    EOLFullLSTM,\n",
        "    train_eol_full_lstm,\n",
        "    evaluate_eol_full_lstm,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Full-Trajectory LSTM für EOL-Prediction (FD001-FD004)\n",
        "\n",
        "Dieses Notebook trainiert ein LSTM-Modell für EOL-Prediction auf den kompletten Trajektorien aller Engines (nicht nur Tail-Samples).\n",
        "\n",
        "**Features:**\n",
        "- Sliding-Window über alle Zyklen jeder Engine\n",
        "- RUL wird auf max_rul=125 gecappt (NASA-Style)\n",
        "- Engine-basierter Split (keine Data Leakage)\n",
        "- NASA PHM08 Score Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "[1] Loading CMAPSS Data (FD001-FD004)\n",
            "============================================================\n",
            "Loading FD001...\n",
            "New columns successfully added. Current number of columns: 33\n",
            "   Effizienz_HPC_Proxy  EGT_Drift  Fan_HPC_Ratio  RUL\n",
            "0             0.941013        0.2       0.403737  191\n",
            "1             0.943169        0.2       0.403406  190\n",
            "2             0.942554       -1.8       0.404505  189\n",
            "3             0.943025        0.2       0.405834  188\n",
            "4             0.942581        1.2       0.405831  187\n",
            "  FD001: 20631 rows, 100 engines\n",
            "Loading FD002...\n",
            "[ConditionID] Found 7 unique (S1_r, S2_r, S3_r) combos in TRAIN.\n",
            "[ConditionID] Train ConditionIDs: [0 1 2 3 4 5 6]\n",
            "[ConditionID] Test  ConditionIDs: [0 1 2 3 4 5 6]\n",
            "New columns successfully added. Current number of columns: 33\n",
            "   Effizienz_HPC_Proxy  EGT_Drift  Fan_HPC_Ratio  RUL\n",
            "0             0.940506        6.8       0.408741  148\n",
            "1             0.941593        2.8       0.406364  147\n",
            "2             0.934608      -18.2       0.427536  146\n",
            "3             0.944099        1.8       0.405833  145\n",
            "4             0.938646      -18.2       0.427022  144\n",
            "  FD002: 53759 rows, 260 engines\n",
            "Loading FD003...\n",
            "New columns successfully added. Current number of columns: 33\n",
            "   Effizienz_HPC_Proxy  EGT_Drift  Fan_HPC_Ratio  RUL\n",
            "0             0.942849       -0.6       0.405728  258\n",
            "1             0.942061        0.4       0.405442  257\n",
            "2             0.941562       -0.6       0.405839  256\n",
            "3             0.941067        0.4       0.405472  255\n",
            "4             0.942027        0.4       0.403920  254\n",
            "  FD003: 24720 rows, 100 engines\n",
            "Loading FD004...\n",
            "[ConditionID] Found 7 unique (S1_r, S2_r, S3_r) combos in TRAIN.\n",
            "[ConditionID] Train ConditionIDs: [0 1 2 3 4 5 6]\n",
            "[ConditionID] Test  ConditionIDs: [0 1 2 3 4 5 6]\n",
            "New columns successfully added. Current number of columns: 33\n",
            "   Effizienz_HPC_Proxy  EGT_Drift  Fan_HPC_Ratio  RUL\n",
            "0             0.944817       -3.6       0.409162  320\n",
            "1             0.941253       27.4       0.410169  319\n",
            "2             0.938052       -4.6       0.408713  318\n",
            "3             0.940716       -5.6       0.409099  317\n",
            "4             0.938737      -28.6       0.427093  316\n",
            "  FD004: 61249 rows, 249 engines\n",
            "\n",
            "Total: 160359 rows, 260 engines\n"
          ]
        }
      ],
      "source": [
        "# ===================================================================\n",
        "# 1. Daten laden: FD001-FD004\n",
        "# ===================================================================\n",
        "print(\"=\" * 60)\n",
        "print(\"[1] Loading CMAPSS Data (FD001-FD004)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "dfs = []\n",
        "for fd_id in [\"FD001\", \"FD002\", \"FD003\", \"FD004\"]:\n",
        "    print(f\"Loading {fd_id}...\")\n",
        "    df_train, _, _ = load_cmapps_subset(\n",
        "        fd_id,\n",
        "        max_rul=None,  # Kein Clipping im Train (wird später in build_full_eol_sequences gecappt)\n",
        "        clip_train=False,\n",
        "        clip_test=True,  # Test weiter clampen für NASA-Score\n",
        "    )\n",
        "    df_train = create_physical_features(df_train)\n",
        "    # FD_ID als numerisches Feature (0=FD001, 1=FD002, 2=FD003, 3=FD004)\n",
        "    # Wichtig: FD_ID muss numerisch sein, da es als Feature verwendet wird\n",
        "    fd_id_map = {\"FD001\": 0, \"FD002\": 1, \"FD003\": 2, \"FD004\": 3}\n",
        "    df_train[\"FD_ID\"] = fd_id_map[fd_id]\n",
        "    dfs.append(df_train)\n",
        "    print(f\"  {fd_id}: {len(df_train)} rows, {df_train['UnitNumber'].nunique()} engines\")\n",
        "\n",
        "df_train_global = pd.concat(dfs, ignore_index=True)\n",
        "print(f\"\\nTotal: {len(df_train_global)} rows, {df_train_global['UnitNumber'].nunique()} engines\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "[2] Defining Feature Columns\n",
            "============================================================\n",
            "Using 25 features:\n",
            "  Features: Setting1, Setting2, Setting3, Sensor2, Sensor3, Sensor4, Sensor6, Sensor7, Sensor8, Sensor9...\n"
          ]
        }
      ],
      "source": [
        "# ===================================================================\n",
        "# 2. Feature-Liste definieren\n",
        "# ===================================================================\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"[2] Defining Feature Columns\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Numerische Features aus GLOBAL_FEATURE_COLS\n",
        "numeric_cols = df_train_global[GLOBAL_FEATURE_COLS].select_dtypes(\n",
        "    include=[\"number\"]\n",
        ").columns.tolist()\n",
        "\n",
        "feature_cols = numeric_cols\n",
        "print(f\"Using {len(feature_cols)} features:\")\n",
        "if len(feature_cols) > 10:\n",
        "    print(f\"  Features: {', '.join(feature_cols[:10])}...\")\n",
        "else:\n",
        "    print(f\"  Features: {', '.join(feature_cols)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "[3] Building Full-Trajectory Sequences\n",
            "============================================================\n",
            "============================================================\n",
            "[build_full_eol_sequences_from_df] Summary\n",
            "============================================================\n",
            "Num units: 260\n",
            "Using past_len=30, max_rul=125\n",
            "Num feature cols: 25\n",
            "X shape: torch.Size([152819, 30, 25]), y shape: torch.Size([152819]), unit_ids shape: torch.Size([152819])\n",
            "RUL stats (capped at 125): min=0.00, max=125.00, mean=88.47, std=41.50\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ===================================================================\n",
        "# 3. Full-Trajectory Sequenzen bauen\n",
        "# ===================================================================\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"[3] Building Full-Trajectory Sequences\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "X_full, y_full, unit_ids_full = build_full_eol_sequences_from_df(\n",
        "    df=df_train_global,\n",
        "    feature_cols=feature_cols,\n",
        "    past_len=30,\n",
        "    max_rul=125,  # NASA-Style: RUL wird auf 125 gecappt\n",
        "    unit_col=\"UnitNumber\",\n",
        "    cycle_col=\"TimeInCycles\",\n",
        "    rul_col=\"RUL\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "[4] Creating DataLoaders (Engine-based Split)\n",
            "============================================================\n",
            "============================================================\n",
            "[create_full_dataloaders] Engine-based split\n",
            "============================================================\n",
            "Total units: 260\n",
            "Train units: 208, Val units: 52\n",
            "Train samples: 120764, Val samples: 32055\n",
            "Feature scaling: StandardScaler (fitted on train only)\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ===================================================================\n",
        "# 4. Dataloaders erstellen (Engine-basierter Split)\n",
        "# ===================================================================\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"[4] Creating DataLoaders (Engine-based Split)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "train_loader, val_loader, scaler, train_unit_ids, val_unit_ids = create_full_dataloaders(\n",
        "    X=X_full,\n",
        "    y=y_full,\n",
        "    unit_ids=unit_ids_full,\n",
        "    batch_size=256,\n",
        "    engine_train_ratio=0.8,\n",
        "    shuffle_engines=True,\n",
        "    random_seed=42,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "[5] Initializing EOLFullLSTM Model\n",
            "============================================================\n",
            "Model parameters: 60,801\n"
          ]
        }
      ],
      "source": [
        "# ===================================================================\n",
        "# 5. Modell initialisieren\n",
        "# ===================================================================\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"[5] Initializing EOLFullLSTM Model\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "model = EOLFullLSTM(\n",
        "    input_dim=len(feature_cols),\n",
        "    hidden_dim=64,\n",
        "    num_layers=2,\n",
        "    dropout=0.1,\n",
        "    bidirectional=False,\n",
        ")\n",
        "\n",
        "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "[6] Training EOLFullLSTM\n",
            "============================================================\n",
            "============================================================\n",
            "[train_eol_full_lstm] Training Configuration\n",
            "============================================================\n",
            "Learning Rate: 0.0001\n",
            "Weight Decay: 0.0001\n",
            "Patience: 8\n",
            "Device: cpu\n",
            "============================================================\n",
            "[EOL-Full-LSTM] Epoch 1/80 - train_loss: 6951.1298, val_loss: 4621.0978, val_RMSE: 68.1771, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 2/80 - train_loss: 3235.2106, val_loss: 2148.5132, val_RMSE: 46.3661, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 3/80 - train_loss: 1819.3490, val_loss: 1699.7063, val_RMSE: 41.0469, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 4/80 - train_loss: 1354.1923, val_loss: 1070.8498, val_RMSE: 32.5585, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 5/80 - train_loss: 973.4891, val_loss: 964.8297, val_RMSE: 31.0449, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 6/80 - train_loss: 870.1521, val_loss: 867.2064, val_RMSE: 29.4337, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 7/80 - train_loss: 812.3348, val_loss: 830.0580, val_RMSE: 28.8160, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 8/80 - train_loss: 781.6672, val_loss: 785.0938, val_RMSE: 28.0542, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 9/80 - train_loss: 766.6011, val_loss: 791.0711, val_RMSE: 28.1905, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 10/80 - train_loss: 758.1557, val_loss: 792.8061, val_RMSE: 28.2324, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 11/80 - train_loss: 747.9812, val_loss: 762.3782, val_RMSE: 27.6865, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 12/80 - train_loss: 746.7079, val_loss: 777.2159, val_RMSE: 27.9620, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 13/80 - train_loss: 741.8523, val_loss: 772.5541, val_RMSE: 27.8773, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 14/80 - train_loss: 733.9158, val_loss: 760.9526, val_RMSE: 27.6633, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 15/80 - train_loss: 729.3384, val_loss: 803.6252, val_RMSE: 28.4334, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 16/80 - train_loss: 726.0730, val_loss: 793.5619, val_RMSE: 28.2533, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 17/80 - train_loss: 720.6073, val_loss: 740.7621, val_RMSE: 27.2889, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 18/80 - train_loss: 719.2961, val_loss: 781.9386, val_RMSE: 28.0457, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 19/80 - train_loss: 713.9336, val_loss: 742.9043, val_RMSE: 27.3365, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 20/80 - train_loss: 704.7948, val_loss: 733.6386, val_RMSE: 27.1652, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 21/80 - train_loss: 696.6758, val_loss: 716.2208, val_RMSE: 26.8419, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 22/80 - train_loss: 683.7780, val_loss: 743.3425, val_RMSE: 27.3457, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 23/80 - train_loss: 671.9653, val_loss: 724.1248, val_RMSE: 26.9896, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 24/80 - train_loss: 659.7262, val_loss: 703.7788, val_RMSE: 26.6016, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 25/80 - train_loss: 646.1648, val_loss: 692.3496, val_RMSE: 26.3886, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 26/80 - train_loss: 639.3585, val_loss: 690.1487, val_RMSE: 26.3490, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 27/80 - train_loss: 633.4354, val_loss: 709.8400, val_RMSE: 26.7229, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 28/80 - train_loss: 626.5204, val_loss: 675.8410, val_RMSE: 26.0724, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 29/80 - train_loss: 623.7027, val_loss: 684.1359, val_RMSE: 26.2315, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 30/80 - train_loss: 614.1784, val_loss: 648.7351, val_RMSE: 25.5461, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 31/80 - train_loss: 607.8037, val_loss: 641.7250, val_RMSE: 25.4074, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 32/80 - train_loss: 601.7569, val_loss: 650.2268, val_RMSE: 25.5737, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 33/80 - train_loss: 600.2251, val_loss: 670.3744, val_RMSE: 25.9643, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 34/80 - train_loss: 589.7960, val_loss: 609.6410, val_RMSE: 24.7624, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 35/80 - train_loss: 581.4794, val_loss: 632.6992, val_RMSE: 25.2272, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 36/80 - train_loss: 577.3961, val_loss: 610.8892, val_RMSE: 24.7883, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 37/80 - train_loss: 570.2931, val_loss: 611.5472, val_RMSE: 24.7974, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 38/80 - train_loss: 561.2186, val_loss: 629.9715, val_RMSE: 25.1672, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 39/80 - train_loss: 551.4001, val_loss: 585.3692, val_RMSE: 24.2624, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 40/80 - train_loss: 544.7874, val_loss: 561.5085, val_RMSE: 23.7605, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 41/80 - train_loss: 537.6111, val_loss: 566.9286, val_RMSE: 23.8765, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 42/80 - train_loss: 528.7555, val_loss: 565.6574, val_RMSE: 23.8485, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 43/80 - train_loss: 523.8000, val_loss: 572.5355, val_RMSE: 23.9913, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 44/80 - train_loss: 518.9313, val_loss: 572.0942, val_RMSE: 23.9829, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 45/80 - train_loss: 508.6193, val_loss: 556.2719, val_RMSE: 23.6518, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 46/80 - train_loss: 504.9871, val_loss: 546.8049, val_RMSE: 23.4448, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 47/80 - train_loss: 497.8857, val_loss: 539.8397, val_RMSE: 23.2929, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 48/80 - train_loss: 494.7107, val_loss: 558.0032, val_RMSE: 23.6854, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 49/80 - train_loss: 491.0557, val_loss: 525.1289, val_RMSE: 22.9785, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 50/80 - train_loss: 484.9982, val_loss: 510.2358, val_RMSE: 22.6495, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 51/80 - train_loss: 480.1099, val_loss: 536.7151, val_RMSE: 23.2256, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 52/80 - train_loss: 477.7735, val_loss: 521.0598, val_RMSE: 22.8869, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 53/80 - train_loss: 475.2255, val_loss: 507.3730, val_RMSE: 22.5851, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 54/80 - train_loss: 468.4015, val_loss: 537.5698, val_RMSE: 23.2459, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 55/80 - train_loss: 468.2300, val_loss: 508.1340, val_RMSE: 22.6044, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 56/80 - train_loss: 466.2935, val_loss: 509.8081, val_RMSE: 22.6382, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 57/80 - train_loss: 460.8449, val_loss: 495.1672, val_RMSE: 22.3076, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 58/80 - train_loss: 459.5819, val_loss: 504.6241, val_RMSE: 22.5244, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 59/80 - train_loss: 456.9692, val_loss: 501.3237, val_RMSE: 22.4515, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 60/80 - train_loss: 454.2515, val_loss: 498.7425, val_RMSE: 22.3908, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 61/80 - train_loss: 450.2530, val_loss: 499.9882, val_RMSE: 22.4164, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 62/80 - train_loss: 449.9730, val_loss: 486.5599, val_RMSE: 22.1172, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 63/80 - train_loss: 445.8382, val_loss: 499.5182, val_RMSE: 22.4073, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 64/80 - train_loss: 443.6562, val_loss: 481.7809, val_RMSE: 22.0062, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 65/80 - train_loss: 442.5496, val_loss: 512.7939, val_RMSE: 22.6968, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 66/80 - train_loss: 440.3156, val_loss: 525.4967, val_RMSE: 22.9837, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 67/80 - train_loss: 438.5988, val_loss: 473.0863, val_RMSE: 21.8011, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 68/80 - train_loss: 439.7060, val_loss: 485.2993, val_RMSE: 22.0900, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 69/80 - train_loss: 433.2920, val_loss: 475.7863, val_RMSE: 21.8670, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 70/80 - train_loss: 435.7181, val_loss: 489.4390, val_RMSE: 22.1788, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 71/80 - train_loss: 430.9851, val_loss: 481.8042, val_RMSE: 21.9959, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 72/80 - train_loss: 429.6509, val_loss: 519.4600, val_RMSE: 22.8480, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 73/80 - train_loss: 427.7602, val_loss: 464.8559, val_RMSE: 21.6202, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 74/80 - train_loss: 427.3724, val_loss: 496.0293, val_RMSE: 22.3332, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 75/80 - train_loss: 424.2613, val_loss: 462.7429, val_RMSE: 21.5616, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 76/80 - train_loss: 422.6713, val_loss: 461.3806, val_RMSE: 21.5372, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 77/80 - train_loss: 419.4164, val_loss: 481.2414, val_RMSE: 21.9902, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 78/80 - train_loss: 421.1318, val_loss: 461.2660, val_RMSE: 21.5303, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 79/80 - train_loss: 417.3870, val_loss: 475.0231, val_RMSE: 21.8541, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Epoch 80/80 - train_loss: 415.5923, val_loss: 476.3717, val_RMSE: 21.8700, lr: 1.00e-04\n",
            "[EOL-Full-LSTM] Loaded best model from epoch 78 with val_loss=461.2660\n",
            "[Plot] Saved training curves to ..\\results\\eol_full_lstm\\training_curves_fd001_fd004.png\n",
            "============================================================\n",
            "[train_eol_full_lstm] Training Complete\n",
            "============================================================\n",
            "Best val_loss: 461.2660 (at epoch 78)\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ===================================================================\n",
        "# 6. Training\n",
        "# ===================================================================\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"[6] Training EOLFullLSTM\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "model, history = train_eol_full_lstm(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    num_epochs=80,\n",
        "    lr=1e-4,\n",
        "    weight_decay=1e-4,\n",
        "    patience=8,\n",
        "    device=device,\n",
        "    results_dir=\"../results/eol_full_lstm\",\n",
        "    run_name=\"fd001_fd004\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "[7] Evaluating EOLFullLSTM\n",
            "============================================================\n",
            "============================================================\n",
            "[evaluate_eol_full_lstm] Pointwise Metrics\n",
            "============================================================\n",
            "MSE: 463.5554\n",
            "RMSE: 21.5303 cycles\n",
            "MAE: 15.8168 cycles\n",
            "Bias: -2.5599 cycles\n",
            "R²: 0.7301\n",
            "============================================================\n",
            "[evaluate_eol_full_lstm] EOL/NASA Metrics (per Engine, last cycle)\n",
            "============================================================\n",
            "RMSE_eol: 17.4663 cycles\n",
            "MAE_eol: 12.9049 cycles\n",
            "Bias_eol: 11.6153 cycles\n",
            "NASA Score (sum): 995.09\n",
            "NASA Score (mean): 19.1363\n",
            "Num engines: 52\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ===================================================================\n",
        "# 7. Evaluation\n",
        "# ===================================================================\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"[7] Evaluating EOLFullLSTM\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "metrics = evaluate_eol_full_lstm(\n",
        "    model=model,\n",
        "    val_loader=val_loader,\n",
        "    device=device,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "[8] Final Summary\n",
            "============================================================\n",
            "Pointwise Metrics (all validation samples):\n",
            "  RMSE: 21.5303 cycles\n",
            "  MAE: 15.8168 cycles\n",
            "  Bias: -2.5599 cycles\n",
            "  R²: 0.7301\n",
            "  NASA Score (pointwise, sum): 605393.50\n",
            "  NASA Score (pointwise, mean): 18.8861\n",
            "\n",
            "EOL Metrics (per engine, last cycle):\n",
            "  RMSE_eol: 17.4663 cycles\n",
            "  MAE_eol: 12.9049 cycles\n",
            "  Bias_eol: 11.6153 cycles\n",
            "  NASA Score (EOL, sum): 995.09\n",
            "  NASA Score (EOL, mean): 19.1363\n",
            "  Num engines: 52\n",
            "============================================================\n",
            "Training complete!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ===================================================================\n",
        "# 8. Zusammenfassung\n",
        "# ===================================================================\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"[8] Final Summary\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Pointwise Metrics (all validation samples):\")\n",
        "print(f\"  RMSE: {metrics['pointwise']['rmse']:.4f} cycles\")\n",
        "print(f\"  MAE: {metrics['pointwise']['mae']:.4f} cycles\")\n",
        "print(f\"  Bias: {metrics['pointwise']['bias']:.4f} cycles\")\n",
        "print(f\"  R²: {metrics['pointwise']['r2']:.4f}\")\n",
        "print(f\"  NASA Score (pointwise, sum): {metrics['nasa_pointwise']['score_sum']:.2f}\")\n",
        "print(f\"  NASA Score (pointwise, mean): {metrics['nasa_pointwise']['score_mean']:.4f}\")\n",
        "\n",
        "if \"eol\" in metrics:\n",
        "    print(\"\\nEOL Metrics (per engine, last cycle):\")\n",
        "    print(f\"  RMSE_eol: {metrics['eol']['rmse']:.4f} cycles\")\n",
        "    print(f\"  MAE_eol: {metrics['eol']['mae']:.4f} cycles\")\n",
        "    print(f\"  Bias_eol: {metrics['eol']['bias']:.4f} cycles\")\n",
        "    print(f\"  NASA Score (EOL, sum): {metrics['eol']['nasa_score_sum']:.2f}\")\n",
        "    print(f\"  NASA Score (EOL, mean): {metrics['eol']['nasa_score_mean']:.4f}\")\n",
        "    print(f\"  Num engines: {metrics['eol']['num_engines']}\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Training complete!\")\n",
        "print(\"=\" * 60)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "turbine_ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
